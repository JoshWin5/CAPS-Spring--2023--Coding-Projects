{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr-gwg79wTkX",
        "outputId": "385ca7d9-e88a-418f-ef8b-674b21684dd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the next cell, make sure you've downloaded the proper zip file (look at Discord) and put it in your Google Drive. Remeber that once your drive is mounted you can right click the files and folders on the left of the screen to find their* paths*.\n",
        "\n",
        "You may need to change the path inside the read_csv function below to a different path."
      ],
      "metadata": {
        "id": "lyFuzJU1ooHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Pandas library and convert csv file to pandas dataframe\n",
        "import pandas as pd\n",
        "\n",
        "#CHANGE THE PATH HERE IF NEEDED\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Supreme Court Database/SCDB_2022_01_justiceCentered_Citation.csv.zip', encoding='iso-8859-1')"
      ],
      "metadata": {
        "id": "9TEVbIjS0ywK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237ee88b-9f67-44c0-c5bb-cb50cda12df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6faff3ed820e>:5: DtypeWarning: Columns (6,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/gdrive/MyDrive/Supreme Court Database/SCDB_2022_01_justiceCentered_Citation.csv.zip', encoding='iso-8859-1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import Pandas library and convert csv file to pandas dataframe\n",
        "import pandas as pd\n",
        "\n",
        "#CHANGE THE PATH HERE IF NEEDED\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/SCDB_2022_01_justiceCentered_Citation.csv', encoding='iso-8859-1')"
      ],
      "metadata": {
        "id": "loE3n1GXReIt",
        "outputId": "30cab3da-e102-4060-e137-e67f22e1025a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9b02ee4dfe75>:5: DtypeWarning: Columns (6,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/gdrive/MyDrive/SCDB_2022_01_justiceCentered_Citation.csv', encoding='iso-8859-1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the names of justices\n",
        "df['justiceName'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIcND_5J3Uhc",
        "outputId": "07f43422-4a36-4447-f035-e117637989c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HHBurton', 'RHJackson', 'WODouglas', 'FFrankfurter', 'SFReed',\n",
              "       'HLBlack', 'WBRutledge', 'FMurphy', 'FMVinson', 'TCClark',\n",
              "       'SMinton', 'EWarren', 'JHarlan2', 'WJBrennan', 'CEWhittaker',\n",
              "       'PStewart', 'BRWhite', 'AJGoldberg', 'AFortas', 'TMarshall',\n",
              "       'WEBurger', 'HABlackmun', 'LFPowell', 'WHRehnquist', 'JPStevens',\n",
              "       'SDOConnor', 'AScalia', 'AMKennedy', 'DHSouter', 'CThomas',\n",
              "       'RBGinsburg', 'SGBreyer', 'JGRoberts', 'SAAlito', 'SSotomayor',\n",
              "       'EKagan', 'NMGorsuch', 'BMKavanaugh', 'ACBarrett'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe from the origional dataframe called df_Roberts, where all entries are of justice Roberts\n",
        "df_Roberts = df[(df['justiceName'] == 'JGRoberts')]"
      ],
      "metadata": {
        "id": "fcuEDXrO54w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the direction column in our new Roberts dataframe\n",
        "df_Roberts['direction']"
      ],
      "metadata": {
        "id": "nQ2A-AD9n23-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and get the sum of the values in this column but using the sum() function\n",
        "# NOTE: This cell will NOT work properly! That's okay.\n",
        "sum(df_Roberts['direction'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NspLEHHQpedv",
        "outputId": "a6cdf397-12a2-49b5-84fe-254223605ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Why didn't it give us a number? Let's check to see the different unique values in the direction column of our dataframe:\n",
        "df_Roberts['direction'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTOO8Tvn6BGV",
        "outputId": "45946915-6196-4910-db82-303e3069f461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.,  1., nan])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our sum function didn't work because of the nan values inside the column. So, we want to get rid of those.\n",
        "\n",
        "# Here we will reassign our Roberts dataframe to only contain rows where the direction column's value is greater than zero.\n",
        "df_Roberts = df_Roberts[df_Roberts['direction'] > 0]"
      ],
      "metadata": {
        "id": "-rPTwvbpp67H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if nan values are gone\n",
        "df_Roberts['direction'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUC1dZFCqj2c",
        "outputId": "78ec6d99-f88a-4dfe-9a2d-5ccebfd7e092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sum of the column\n",
        "roberts_sum = sum(df_Roberts['direction'])"
      ],
      "metadata": {
        "id": "Vhgk7OpKrU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average Roberts' sum by dividing it by the length of entries in the column\n",
        "\n",
        "score = roberts_sum / len(df_Roberts['direction'])"
      ],
      "metadata": {
        "id": "ta8seOOKrgmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does this number represent? Can you think of other ways, using the csv, to measure something like this?\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peP0bhGFrvog",
        "outputId": "a892bdbb-24a7-489b-8d3e-08577197df56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4152473641524737"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_case = df[(df['caseId'] == '2021-069')]\n",
        "df_case"
      ],
      "metadata": {
        "id": "yr2am1M59NXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_case[\"decisionDirection\"][82009]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECubX_TOBHqv",
        "outputId": "50906079-1fef-4be4-d4f1-70147f6e2231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = 1.0\n",
        "is_correct=2.0\n",
        "actual = df_case[\"decisionDirection\"][82009]"
      ],
      "metadata": {
        "id": "xz_kdD_OImY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(prediction == actual): \n",
        "  is_correct= True\n",
        "else:\n",
        "  is_correct = False\n",
        "is_correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUixn169B9Uj",
        "outputId": "9b82109d-e88b-4a16-98ad-0760775ca974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_correct(prediction, actual):\n",
        "  \n",
        "  if(prediction == actual):\n",
        "    prediction = True\n",
        "    return prediction\n",
        "  else:\n",
        "    prediction = False\n",
        "    return prediction\n",
        "\n",
        "  return is_correct"
      ],
      "metadata": {
        "id": "C2KT947kGD-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_correct (\"pizza\", \"apple\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE3XDnDmI5Cj",
        "outputId": "8ef59479-a78e-4053-837d-9bfc522615c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It Works Now"
      ],
      "metadata": {
        "id": "iuXbViWdh5Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Barret = df[(df['justiceName']=='ACBarrett')]\n",
        "df_Barret"
      ],
      "metadata": {
        "id": "fEsSHQ4iK5hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_correct(decisionDirection, actual=2.0):\n",
        "    if(decisionDirection == actual):\n",
        "      prediction = True\n",
        "    else:\n",
        "      prediction = False\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "EsDIV5N2h3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def base_model_score(df_len, true_sum):\n",
        "  return true_sum / df_len"
      ],
      "metadata": {
        "id": "gPAab8WZRjMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_Barret():\n",
        "  true_sum = 0\n",
        "  df_Barret = df[(df['justiceName']=='ACBarrett')]\n",
        "  for x in range(len( df_Barret)):\n",
        "    df_Barret = df_Barret[df_Barret['decisionDirection'] != \"nan\"]\n",
        "  \n",
        "    decisionDirection = df_Barret['decisionDirection'].iloc[x-1]\n",
        "    prediction = is_correct(decisionDirection, 2)\n",
        "  \n",
        "    # print (f\"Decision Direction: {actual}, Actual: {decisionDirection}, Prediction: {prediction}\")\n",
        "\n",
        "    if prediction:\n",
        "      true_sum += 1\n",
        "\n",
        "  score_1 = base_model_score(len(df_Barret), true_sum)\n",
        "\n",
        "  print (f\"True Sum: {true_sum}\")\n",
        "  print (f\"Score: {score_1}\")"
      ],
      "metadata": {
        "id": "nxpWqTVP43e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_Barret()"
      ],
      "metadata": {
        "id": "xx99vbRkDTDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a282037-ea1e-43db-d4b0-c0805918df28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Sum: 47\n",
            "Score: 0.36153846153846153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Work on finding average scores of Supreme court in general"
      ],
      "metadata": {
        "id": "2SFreu0ZsX_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "judges = ['HHBurton', 'RHJackson', 'WODouglas', 'FFrankfurter', 'SFReed',\n",
        "       'HLBlack', 'WBRutledge', 'FMurphy', 'FMVinson', 'TCClark',\n",
        "       'SMinton', 'EWarren', 'JHarlan2', 'WJBrennan', 'CEWhittaker',\n",
        "       'PStewart', 'BRWhite', 'AJGoldberg', 'AFortas', 'TMarshall',\n",
        "       'WEBurger', 'HABlackmun', 'LFPowell', 'WHRehnquist', 'JPStevens',\n",
        "       'SDOConnor', 'AScalia', 'AMKennedy', 'DHSouter', 'CThomas',\n",
        "       'RBGinsburg', 'SGBreyer', 'JGRoberts', 'SAAlito', 'SSotomayor',\n",
        "       'EKagan', 'NMGorsuch', 'BMKavanaugh', 'ACBarrett']\n",
        "\n",
        "score_list = []\n",
        "\n",
        "for i in range(len(judges)):\n",
        "  df_ingeneral = df[(df['justiceName'] == judges[i])]\n",
        "  df_ingeneral = df_ingeneral[df_ingeneral['decisionDirection'] > 0]\n",
        "  total_sum = sum(df_ingeneral['decisionDirection'])\n",
        "  score = total_sum / len(df_ingeneral['decisionDirection'])\n",
        "  print(judges[i])\n",
        "  print(score)\n",
        "  score_list.append(score)\n",
        "\n",
        "score_2 = sum(score_list) /  len(score_list)\n",
        "print(f\"Average Score: {score_2}\")"
      ],
      "metadata": {
        "id": "rZHWUX-1s43-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "print(f\"Random Score: {1+random.random()}\")\n",
        "print(f\"Average Score: {score_2}\")\n",
        "# random.choice(judges)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4fJIZW9yETr",
        "outputId": "246a49de-8507-459e-c870-b91de8cad81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Score: 1.4717161532463923\n",
            "Average Score: 1.5480324039529338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "judges = ['ACBarrett', 'RHJackson',  'JGRoberts', 'CThomas', 'SAAlito', 'SSotomayor', 'EKagan', 'NMGorsuch', 'BMKavanaugh']\n",
        "\n",
        "score_list = []\n",
        "\n",
        "\n",
        "df_ingeneral = df[(df['justiceName'] == 'ACBarrett')]\n",
        "df_ingeneral = df_ingeneral[df_ingeneral['decisionDirection'] > 0]\n",
        "total_sum = sum(df_ingeneral['decisionDirection'])\n",
        "score = total_sum / len(df_ingeneral['decisionDirection'])\n",
        "print(judges[i])\n",
        "print(score)\n",
        "score_list.append(score)\n",
        "\n",
        "\n",
        "\n",
        "print(df_ingeneral)"
      ],
      "metadata": {
        "id": "1shUNLslC9vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Barret"
      ],
      "metadata": {
        "id": "0pEdQq9220-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction Model"
      ],
      "metadata": {
        "id": "AOfAy5As7QAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(predict_party, judge_name, case_Number):\n",
        "  right = 0\n",
        "  wrong = 0\n",
        "  if predict_party == 2.0:\n",
        "    predicted_vote = 'Liberal'\n",
        "  if predict_party == 1.0:\n",
        "    predicted_vote = 'Conservative'\n",
        "\n",
        "  df_caseId = df[(df['caseId'] == case_Number)]\n",
        "  df_caseId = df_caseId[(df_caseId['direction']) > 0 ]\n",
        "\n",
        "  judge_data = df_caseId[df_caseId['justiceName']==judge_name]\n",
        "  for index, row in df_caseId.iterrows():\n",
        "    if row['justiceName'] != judge_name:\n",
        "      continue\n",
        "\n",
        "    if row['direction'] == 2.0:\n",
        "      actual_vote = 'Liberal'\n",
        "    if row['direction'] == 1.0:\n",
        "      actual_vote = 'Conservative'\n",
        "\n",
        "    if row['direction'] == predict_party:\n",
        "      print(f\"Prediction is correct for judge: {judge_name}, case id: {row['caseId']}, Predicted vote: {predicted_vote}, Actual vote: {actual_vote}\")\n",
        "      right =+ 1\n",
        "    else:\n",
        "      print(f\"Prediction is incorrect for judge: {judge_name}, case id: {row['caseId']}, Predicted vote: {predicted_vote}, Actual vote: {actual_vote}\")\n",
        "      wrong =+1\n",
        "  return right, wrong\n",
        "\n",
        "  # if right > wrong:\n",
        "  #   print(\"Court Decision's Actual Decision on Average is Liberal\")\n",
        "  # else:\n",
        "  #   print(\"Court Decision's Actual Decision on Average is Conservative\")\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "NVplAK73QAFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_model():\n",
        "  liberal = 0\n",
        "  conservative = 0\n",
        "  judges = ['HHBurton', 'RHJackson', 'WODouglas', 'FFrankfurter', 'SFReed',\n",
        "       'HLBlack', 'WBRutledge', 'FMurphy', 'FMVinson', 'TCClark',\n",
        "       'SMinton', 'EWarren', 'JHarlan2', 'WJBrennan', 'CEWhittaker',\n",
        "       'PStewart', 'BRWhite', 'AJGoldberg', 'AFortas', 'TMarshall',\n",
        "       'WEBurger', 'HABlackmun', 'LFPowell', 'WHRehnquist', 'JPStevens',\n",
        "       'SDOConnor', 'AScalia', 'AMKennedy', 'DHSouter', 'CThomas',\n",
        "       'RBGinsburg', 'SGBreyer', 'JGRoberts', 'SAAlito', 'SSotomayor',\n",
        "       'EKagan', 'NMGorsuch', 'BMKavanaugh', 'ACBarrett']\n",
        "  score_list = []\n",
        "  court_decision = 0\n",
        "  for i in range(len(judges)):\n",
        "    party = 0.0\n",
        "    df_ingeneral = df[(df['justiceName'] == judges[i])]\n",
        "    df_ingeneral = df_ingeneral[df_ingeneral['decisionDirection'] > 0]\n",
        "    total_sum = sum(df_ingeneral['decisionDirection'])\n",
        "    score = total_sum / len(df_ingeneral['decisionDirection'])\n",
        "    \n",
        "    import random\n",
        "    randomScore = 1+random.random()\n",
        "    print(judges[i])\n",
        "    print(f\"Average Score: {score}\")\n",
        "    print(f\"Random Score: {randomScore}\")\n",
        "\n",
        "    if score > randomScore:\n",
        "      print(\"Guess: Liberal\")\n",
        "      liberal =+ 1\n",
        "      party = 2.0\n",
        "    else:\n",
        "      print(\"Guess: Conservative\")\n",
        "      conservative =+ 1\n",
        "      party = 1.0\n",
        "    score_list.append(score)\n",
        "\n",
        "    #validation(party,judges[i], '2020-006')\n",
        "\n",
        "  if liberal > conservative:\n",
        "    print(\"Court  Decision's Predicted Decision on Average is Liberal\")\n",
        "    court_decision = 2\n",
        "  else:\n",
        "    print(\"Court Decision's Predicted Decision on Average is Conservative\")\n",
        "    court_decision = 1\n",
        "  return court_decision"
      ],
      "metadata": {
        "id": "Z9y2U7SCtJcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Barret = df[(df['justiceName']=='ACBarrett')]\n",
        "right = 0 \n",
        "wrong = 0\n",
        "df_Barret_reset = df_Barret.reset_index()\n",
        "for i in range(len(df_Barret)):\n",
        "  \n",
        "  if prediction_model() == df_Barret_reset['decisionDirection'][i]:\n",
        "    right = right + 1\n",
        "    accuracy = right/ len(df_Barret)\n",
        "  if right >= wrong:\n",
        "   print(\"Court Decision's Actual Decision on Average is Liberal\")\n",
        "  else:\n",
        "   print(\"Court Decision's Actual Decision on Average is Conservative\") \n",
        "   \n",
        "print(f\"Accuracy percentage: {accuracy}\")\n",
        "\n",
        "\n",
        "    # score_3 = sum(score_list) /  len(score_list)\n",
        "    # import random\n",
        "    # print(f\"Average Score of the Court as a whole: {score_3}\")\n",
        "    # df_caseId"
      ],
      "metadata": {
        "id": "aPe2mAE5FXZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "IMPORTANT VARIABLES I FOUND\n",
        "\n",
        "Majority and Minority Voting by Justice: 1\tdissent, 2\tmajority\n",
        "\n",
        "Split Vote: 1\tfirst vote on issue/legal provision, 2\tsecond vote on issue/legal provision\n",
        "\n",
        "Formal Alteration of Precedent: 0\tno determinable alteration of precedent, \n",
        "1\tprecedent altered\n",
        "\n",
        "Unusual Disposition: 0\tno unusual disposition specified, 1\tunusual disposition\n",
        "\n",
        "Decision Direction Dissent: 0\tdissent in opposite direction, 1\tmajority and dissent in same direction\n",
        "\n",
        "Issue Area: 1\tCriminal Procedure,\n",
        "2\tCivil Rights,\n",
        "3\tFirst Amendment,\n",
        "4\tDue Process,\n",
        "5\tPrivacy,\n",
        "6\tAttorneys,\n",
        "7\tUnions,\n",
        "8\tEconomic Activity,\n",
        "9\tJudicial Power,\n",
        "10\tFederalism,\n",
        "11\tInterstate Relations,\n",
        "12\tFederal Taxation,\n",
        "13\tMiscellaneous,\n",
        "14\tPrivate Action\n",
        "\n",
        "ORAL ARGUMENTS: https://www.supremecourt.gov/oral_arguments/argument_audio/2022"
      ],
      "metadata": {
        "id": "W14D6X0V08Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = df[['caseId','justiceName','petitioner', 'respondent', 'caseSource', 'caseOrigin', 'issue', 'issueArea','decisionDirection']]\n",
        "df_new"
      ],
      "metadata": {
        "id": "u22I0msDtTko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "df_filtered = df.dropna(subset=['issueArea', 'direction'])\n",
        "\n",
        "X = df_filtered['issueArea'].values.reshape(-1, 1)\n",
        "y = df_filtered['direction']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create an MLPClassifier\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the input data\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions on the test data\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix and accuracy\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the confusion matrix and accuracy\n",
        "print(cm)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "ZqwtBXMbt3gv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00a17d0-c897-42b7-9a73-91604579ec7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4789 6229]\n",
            " [3820 8360]]\n",
            "0.5668161048366238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Prediction Model"
      ],
      "metadata": {
        "id": "5nffEYN8G-V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.arrays import categorical\n",
        "categorical = ['justice','petitioner', 'respondent', 'caseSource', 'caseOrigin', 'issue', 'issueArea']"
      ],
      "metadata": {
        "id": "YqxEh_6oMO0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
        "X_categorical = OneHotEncoder().fit_transform(df_filtered[categorical].values).toarray()\n",
        "#X = input area \n",
        "\n",
        "X_categorical[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AASfOsG9GCTO",
        "outputId": "127ec1fe-077d-4d43-a7b8-ad085fd4d3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "df_filtered = df.dropna(subset=['justice','petitioner', 'respondent', 'caseSource', 'caseOrigin', 'issue', 'issueArea','direction'])\n",
        "\n",
        "X = df_filtered[['justice','petitioner', 'respondent', 'caseSource', 'caseOrigin', 'issue', 'issueArea']].values\n",
        "y = df_filtered['direction']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_categorical, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# Create an MLPClassifier\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the input data\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions on the test data\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix and accuracy\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the confusion matrix and accuracy\n",
        "print(cm)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "Ep6PyjrdKvNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment:\n",
        "\n",
        "Download the oral arguments and convert that to text.\n",
        "\n",
        "How to make a document into something that the computer can learn.\n",
        "\n"
      ],
      "metadata": {
        "id": "nEtbZPFqTrwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use this for the assignment\n",
        "sentence = \"This is a sentence\"\n",
        "end= sentence.split(\"is\")[2]"
      ],
      "metadata": {
        "id": "ZOsNu1b2UHBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GtQY1Z06UybC",
        "outputId": "18073ea6-10db-4258-d16b-284e4002f322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' a sentence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns = ['words'])"
      ],
      "metadata": {
        "id": "tJH3159LPOOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O3KE2uIPGn7",
        "outputId": "61ad8dd8-44e1-4686-8786-eb3537713eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2020/20-543_hgci.pdf\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "with open(\"20-543_hgci.pdf\", \"wb\") as file:\n",
        "    file.write(response.content)"
      ],
      "metadata": {
        "id": "CzCCOaShcXmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "# Open the PDF file in read-binary mode\n",
        "with open('20-543_hgci.pdf', 'rb') as file:\n",
        "\n",
        "    # Create a PDF reader object\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Get the total number of pages in the PDF file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    # Extract text from each page\n",
        "    text = ''\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "IW2B9X6CbMj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_split = text.strip().replace('\\n','').split(\"ROBERTS:\")\n",
        "len(text_split)"
      ],
      "metadata": {
        "id": "Xt02YpM7L6GI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81ade71-e0b3-4b64-8665-4a3903c8e064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = ['MR.','MS',':']\n",
        "strings = []\n",
        "for stop_word in stop_words:\n",
        "  strings.append(text_split[2].split(stop_word)[0])\n",
        "if len(strings[0]) > len(strings[1]):\n",
        "  print(strings[1])\n",
        "else:\n",
        "  print(strings[0])\n",
        "  "
      ],
      "metadata": {
        "id": "z3KWi5O6MxBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865fd37f-e0ae-4455-ef3a-de1ecfa2a9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Counsel, as I think you confirmed in this opening statement, you rely heavily on the legislative history, the congressional purpose, the post- enactment history, and there was a time when this Court also relied on those sources, but this -- this is not that time. And what is the best case you can cite from recent years for your -- your general approach? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a subset of modern court (Barret Subset data)\n",
        "\n",
        "Two columns: 1st Colums Words, wnd Column Word embbedings\n",
        "\n",
        "Every oral argument for every case in that dataframe \n",
        "\n",
        "Make a list for every justice \n",
        "\n",
        "Takeing those columns into embbed words"
      ],
      "metadata": {
        "id": "Wv9HJ4h0XZdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0-c2fVC5HpA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "from urllib.parse import urljoin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTTFKsDz77UW"
      },
      "outputs": [],
      "source": [
        "pdf_links = [\"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2009/08-1371.pdf\", \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2009/08-1332.pdf\", \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2009/09-367.pdf\", \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2009/09-337.pdf\", \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2009/09-497.pdf\", \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2009/09-448.pdf\", \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2009/09-475.pdf\", \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2009/09-559.pdf\"]\n",
        "for link in soup.find_all(\"a\"):\n",
        "    href = link.get(\"href\")\n",
        "    if href and href.endswith(\".pdf\"):\n",
        "        absolute_url = urljoin(base_url, href)\n",
        "        pdf_links.append(absolute_url)\n",
        "        filename = os.path.basename(absolute_url)\n",
        "        file_path = os.path.join(\"/content/gdrive/MyDrive/Supreme Court Database\", filename)\n",
        "        print(f\"Downloading: {filename}\")\n",
        "        response = requests.get(absolute_url)\n",
        "        with open(file_path, \"wb\") as file:\n",
        "            file.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOOyFDor_Dc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505c0907-4fee-41c9-eae6-0e81ad2150cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloads completed.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "print(\"Downloads completed.\")\n",
        "len(pdf_links)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Split Model"
      ],
      "metadata": {
        "id": "sBTwi1PijTLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://www.supremecourt.gov/oral_arguments/argument_transcripts/2020/20-543_hgci.pdf\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "with open(\"20-543_hgci.pdf\", \"wb\") as file:\n",
        "    file.write(response.content)"
      ],
      "metadata": {
        "id": "79eLFHjNjRNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_split = text.strip().replace('\\n','').split(\"ROBERTS:\")"
      ],
      "metadata": {
        "id": "rfETzO0Dic60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = ['MR.','MS',':']\n",
        "strings = []\n",
        "for stop_word in stop_words:\n",
        "  strings.append(text_split[2].split(stop_word)[0])\n",
        "if len(strings[0]) > len(strings[1]):\n",
        "  print(strings[1])\n",
        "else:\n",
        "  print(strings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZPFzYJait2T",
        "outputId": "ee9cb156-c9a0-4071-baff-cff019bcba7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Counsel, as I think you confirmed in this opening statement, you rely heavily on the legislative history, the congressional purpose, the post- enactment history, and there was a time when this Court also relied on those sources, but this -- this is not that time. And what is the best case you can cite from recent years for your -- your general approach? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "5deY6xxcR35Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvNkD10MROhc",
        "outputId": "17631b4a-94f6-485f-b06d-3c474970f19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/content/gdrive/MyDrive/Supreme Court DatabaseND00-00429.rtf', binary=True)\n",
        "\n",
        "text = '/content/gdrive/MyDrive/Supreme Court DatabaseND00-00429.rtf'\n",
        "words = text.split()\n",
        "vectors = []\n",
        "for word in words:\n",
        "    try:\n",
        "       vector = word_vectors[word]\n",
        "       vectors.append(vector)\n",
        "    except KeyError:\n",
        "        pass\n",
        "if vectors:\n",
        "    issue_embedding = np.mean(vectors, axis=0)\n",
        "    print(issue_embedding)\n",
        "else:\n",
        "     print(np.zeros(100))"
      ],
      "metadata": {
        "id": "kgwDvFngaluX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value = '/content/gdrive/MyDrive/Supreme Court DatabaseND99-01145.rtf'  # Example value containing RTF formatting codes\n",
        "\n",
        "# Remove RTF formatting codes using a regular expression\n",
        "import re\n",
        "value = re.sub(r'{\\\\.*?}', '', value)\n",
        "\n",
        "# Convert the cleaned value to an integer\n",
        "try:\n",
        "    int_value = int(value)\n",
        "except ValueError:\n",
        "    # Handle the case where the cleaned value cannot be converted to an integer\n",
        "    print(\"Error: The value is not a valid integer.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMt6yYI2VFR8",
        "outputId": "98247f58-93f7-4b1f-a0f3-d654a787034f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The value is not a valid integer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/content/gdrive/MyDrive/Supreme Court DatabaseND99-01145.rtf', binary=True)\n",
        "data = df\n",
        "\n",
        "embeddings = []\n",
        "for index, row in data.iterrows():\n",
        "    text = row['Issues']\n",
        "    words = text.split()\n",
        "    vectors = []\n",
        "    for word in words:\n",
        "        try:\n",
        "            vector = word_vectors[word]\n",
        "            vectors.append(vector)\n",
        "        except KeyError:\n",
        "            pass\n",
        "    if vectors:\n",
        "        issue_embedding = np.mean(vectors, axis=0)\n",
        "        embeddings.append(issue_embedding)\n",
        "\n",
        "    else:\n",
        "        embeddings.append(np.zeros(100))\n",
        "df['Issue_Embeddings'] = embeddings"
      ],
      "metadata": {
        "id": "uifrIGj4NvNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ruJOP_hZt9aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['direction'].fillna(-1).unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Agw_9IGuUlt",
        "outputId": "97bf6a7d-7bca-4164-fe29-4c996b1af63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  2., -1.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eRxF4GiuXif",
        "outputId": "68f00703-bf01-4173-d852-ad2ff10d1554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54127, 1)\n",
            "(54127,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_caseId = df[(df['caseId'] == '2020-006')]\n",
        "subset = df_caseId[['caseId', 'decisionDirection', 'justiceName', 'direction']]\n",
        "subset"
      ],
      "metadata": {
        "id": "Dgxureg7I2EW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "55713093-3f4a-4b7d-edf1-11b71885b83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         caseId  decisionDirection  justiceName  direction\n",
              "80890  2020-006                2.0    JGRoberts        2.0\n",
              "80891  2020-006                2.0      CThomas        1.0\n",
              "80892  2020-006                2.0     SGBreyer        2.0\n",
              "80893  2020-006                2.0      SAAlito        1.0\n",
              "80894  2020-006                2.0   SSotomayor        2.0\n",
              "80895  2020-006                2.0       EKagan        2.0\n",
              "80896  2020-006                2.0    NMGorsuch        2.0\n",
              "80897  2020-006                2.0  BMKavanaugh        2.0\n",
              "80898  2020-006                2.0    ACBarrett        NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c7bc99a-5f24-4a7b-bdff-e67248264caa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caseId</th>\n",
              "      <th>decisionDirection</th>\n",
              "      <th>justiceName</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80890</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>JGRoberts</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80891</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>CThomas</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80892</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>SGBreyer</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80893</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>SAAlito</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80894</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>SSotomayor</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80895</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>EKagan</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80896</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NMGorsuch</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80897</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>BMKavanaugh</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80898</th>\n",
              "      <td>2020-006</td>\n",
              "      <td>2.0</td>\n",
              "      <td>ACBarrett</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c7bc99a-5f24-4a7b-bdff-e67248264caa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c7bc99a-5f24-4a7b-bdff-e67248264caa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c7bc99a-5f24-4a7b-bdff-e67248264caa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
        "\n",
        "X_categorical = OneHotEncoder().fit_transform(df_filtered['issueArea'].values.reshape(-1, 1)).toarray()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_categorical, y, test_size=0.3, random_state=42)\n",
        "\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the input data\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions on the test data\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix and accuracy\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the confusion matrix and accuracy\n",
        "print(cm)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrDjZN5YF7xa",
        "outputId": "5e122d6e-f20f-4ab9-9c50-34b0d0ad459a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4999 6019]\n",
            " [3927 8253]]\n",
            "0.5712561427709285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual_vote = df_caseId['direction']\n",
        "actual_vote"
      ],
      "metadata": {
        "id": "kgMj9_WNH1Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Averages of Current Supreme Court Members"
      ],
      "metadata": {
        "id": "__xRy5FNDv66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "judges = ['JGRoberts', 'CThomas','SGBreyer', 'SAAlito', 'SSotomayor', 'EKagan', 'NMGorsuch', 'BMKavanaugh', 'ACBarrett']\n",
        "\n",
        "score_list = []\n",
        "\n",
        "for i in range(len(judges)):\n",
        "  df_ingeneral = df[(df['justiceName'] == judges[i])]\n",
        "  df_ingeneral = df_ingeneral[df_ingeneral['decisionDirection'] > 0]\n",
        "  total_sum = sum(df_ingeneral['decisionDirection'])\n",
        "  score = total_sum / len(df_ingeneral['decisionDirection'])\n",
        "  print(judges[i])\n",
        "  print(score)\n",
        "  score_list.append(score)\n",
        "\n",
        "score_3 = sum(score_list) /  len(score_list)\n",
        "print(f\"Average Score: {score_3}\")"
      ],
      "metadata": {
        "id": "WnQfPo10DvJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "print(f\"Random Score: {1+random.random()}\")\n",
        "print(f\"Average Score: {score_3}\")\n",
        "# random.choice(judges)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a82775-01a2-4780-8133-fe2b87e90f48",
        "id": "BpXAOXf1FR5s"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Score: 1.230069910512808\n",
            "Average Score: 1.51446686153063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STOP HERE"
      ],
      "metadata": {
        "id": "dibTBzIIsBFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['caseId'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKwmdx2G--YM",
        "outputId": "9b6f5728-266c-42fb-fd2d-47225efb8cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1946-001', '1946-002', '1946-003', ..., '2021-067', '2021-068',\n",
              "       '2021-069'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ingeneral['decisionDirection']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AROTDxUuenFW",
        "outputId": "b21c30f4-77b4-4c3d-caee-3e3797c4986c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80853    3.0\n",
              "80862    1.0\n",
              "80871    2.0\n",
              "80880    2.0\n",
              "80889    2.0\n",
              "        ... \n",
              "81978    2.0\n",
              "81987    1.0\n",
              "81996    1.0\n",
              "82005    1.0\n",
              "82014    2.0\n",
              "Name: decisionDirection, Length: 128, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}